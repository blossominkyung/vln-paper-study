## vln-paper-study
This repository is to review vision-language navigation papers for personal study.
However, sometimes I also review multimodal learning, graphml, and other deep learnings. 

### index.
* [Vision-and-Language Navigation](https://github.com/blossominkyung/vln-paper-study/blob/main/README.md#vision-and-laguage-navigation)
* [GraphML](https://github.com/blossominkyung/vln-paper-study/blob/main/README.md#graphml)
* [Multimodal Learning](https://github.com/blossominkyung/vln-paper-study/blob/main/README.md#multimodal-learning)

## papers' list
### Vision-and-Laguage Navigation
* -1. **History Aware Multimodal Transformer for Vision-and-Language Navigation**
   * [review](https://github.com/blossominkyung/vln-paper-study/issues/2)


### GraphML
* -1. **Teaching old labels in Heterogeneous Graphs via Knowledge Transfer Networks**
   * [review](https://github.com/blossominkyung/vln-paper-study/issues/4)
   * [by korean](https://www.blossominkyung.com/deeplearning/ktn)

  
### Multimodal Learning
* -1. **FIBER: Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone**
   * [review](https://github.com/blossominkyung/vln-paper-study/issues/3)
   * [by korean](https://www.blossominkyung.com/deeplearning/fiber)
